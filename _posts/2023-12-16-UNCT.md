---
layout : single
title:  비지도학습:연관성분석
use_math: true
categories: Unsupervised_learning
---
# 1. 비지도학습
- 사람의 도움없이 컴퓨터가 스스로 데이터를 파악하고 규칙을 찾는 방법을 말한다.<br>
-> y값 없이 x값만으로 데이터를 학습하는 방법<br>
- 비지도학습 시에는 비정형 데이터를 학습한다.<br>
- 훈련 정보가 사전에 정답이 레이블 되지 않거나, 구조를 알 수 없는 데이터일때 그 데이터의 의미있는 정보를 추출한다.<br>
데이터세트에서 추론을 도출하고, 레이블이 없는 데이터에 있을 수 있는 숨겨진 구조를 표시한다.<br>

<br>
# 2. 여러가지 비지도학습 알고리즘들
- 비지도학습의 알고리즘은 군집화(clustering), 차원 축소(dimensionality reduction), 연관성 분석(association analysis)에 사용된다.<br>
- Catgorical 데이터에는 연관성 분석, Hidden Markov model이 사용되고, Continuous 데이터에는 군집화와 차원축소가 사용된다.<br>
- 차원축소에는 SVD, PCA등이 사용되고, 군집화에는 K-means, DBSCAN등이 사용된다.<br>
- 연관성분석에는 APriori, FP-Growth등이 사용된다.<br>
<br>
<br>

## 2-3. 연관성 분석
- 연관성 분석은 특정 데이터 세트에서 변수 간의 관계를 발견하기 위한 규칙 기반 학습 방법이다.<br>
-> 하나의 거래나 사건에 포함되어 있는 항목들의 경향을 파악, 상호 연관성을 발견한다.<br>
-> 어떤 개인이나 그룹에 의해 수행된 활동들 중에서 함께 발생하는 것들의 관계를 찾아내는 데이터 분석방법이다.<br>

- 연관성 분석을 위해서는 연관 규칙을 찾아내야한다.
<br>
연관 규칙: 특정사건이 발생했을 때 함께 발생되는 또 다른 규칙<br>
<br>

#### 2-3-1. Apriori 알고리즘
- 연관 규칙 알고리즘 중에서 가장 먼저(1993년에 제안됨), 가장 많이 사용되고 있는 알고리즘이다.<br>
- 모든 품목집합에 대한 지지도를 계산하는 것이 아니라, 최소 지지도 이상의 빈발항목집합을 찾은 후 그것에 대해서만 연관 규칙을 계산한다.<br>
<br>
**연관 규칙을 평가하는 기준**<br>
- 지지도$P(A \cap B)$ <br>
어느 정도 지지도가 있는 항목들 중에서 연관성 규칙을 알아봐야 한다.<br>

- 신뢰도 $P(B|A) = \frac{P(A \cap B)}{P(A)}$ <br>
신뢰도가 1에 가까울 수록 의미있는 연관성을 가지고 있다고 할 수 있다.<br>

- 향상도 $\frac{P(A \cap B)}{P(A) \, P(B)}$ <br>
향상도= 1이면 조건과 결과는 우연, 향상도가 1보다 높으면 연관성이 높다는 것을 의미한다.<br>
<br>

- 진행순서<br>

1. 빈발 품목 집합 생성<br>
- 빈발 품목집합: 각 품목별로 발생 횟수(비율)가 특정 값 이상인 품목을 모은 집합<br>
- 최소 지지도를 설정하여 그 이상의 지지도를 갖는 품목 집합을 찾음<br>
<br>

2. 연관 규칙 생성<br>
- 빈발 품목 집합의 공집합을 제외한 모든 부분집합 중 최소 신뢰도를 넘는 연관 규칙을 찾는다.<br>
- 주로 향상도 1 이상을 주요 규칙으로 채택한다.<br>
<br>

처음부터 너무 낮은 최소 지지도를 선정하는 것은 많은 리소스가 소모된다.(주로 0.5를 많이 사용한다.)<br>
<br>
**Apriori 알고리즘의 장단점**<br>
장점<br>
- 원리가 간단하여 이해하거나 의미를 파악하기 쉽다.<br>
- 유의미한 연관성을 갖는 분야(구매패턴찾기, 동일 설계 추천 등)에 다양한 패턴을 찾아준다.<br>

단점<br>
- 데이터가 커질수록 연산할게 많아져 속도가 느려진다.(이를 보완하기 위해 나온 것이 FP-growth algorithm)<br>
- 너무 많은 연관상품을 나타내준다.<br>
- A->B인지 B->A인지 구분이 어렵다<br>

<br>
apriori 알고리즘 예제이다.<br>
*https://www.delftstack.com/ko/howto/python/apriori-algorithm-python/*의 코드를 이용했다.<br>

```python
pip install apyori #필요한 패키지를 다운
```

    Collecting apyori
      Downloading apyori-1.1.2.tar.gz (8.6 kB)
      Preparing metadata (setup.py): started
      Preparing metadata (setup.py): finished with status 'done'
    Building wheels for collected packages: apyori
      Building wheel for apyori (setup.py): started
      Building wheel for apyori (setup.py): finished with status 'done'
      Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5975 sha256=592ac3f19be296b15b38afcef99e98dbca7d47a3c0f1b680c4230fc6b4a755a8
      Stored in directory: c:\users\hsk20\appdata\local\pip\cache\wheels\1b\02\6c\a45230be8603bd95c0a51cd2b289aefdd860c1a100eab73661
    Successfully built apyori
    Installing collected packages: apyori
    Successfully installed apyori-1.1.2
    Note: you may need to restart the kernel to use updated packages.
    


```python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from apyori import apriori
market_data = pd.read_csv("Market_Basket_Optimisation.csv", header=None)# kaggle의 Market_Basket_Optimisation데이터 사용
```


```python
transacts = []
for i in range(0, len(market_data)):
    transacts.append([str(market_data.values[i, j]) for j in range(0, 20)])
```


```python
rules = apriori(
    transactions=transacts,
    min_support=0.003,
    min_confidence=0.2,
    min_lift=3,
    min_length=2,
    max_length=2,
)
```


```python
def inspect(output):
    Left_Hand_Side = [tuple(result[2][0][0])[0] for result in output]
    support = [result[1] for result in output] # 지지도
    confidence = [result[2][0][2] for result in output] #신뢰도
    lift = [result[2][0][3] for result in output] #향상도
    Right_Hand_Side = [tuple(result[2][0][1])[0] for result in output]
    return list(zip(Left_Hand_Side, support, confidence, lift, Right_Hand_Side))


output = list(rules)
output_data = pd.DataFrame(
    inspect(output),
    columns=["Left_Hand_Side", "Support", "Confidence", "Lift", "Right_Hand_Side"],
)
print(output_data)
```

             Left_Hand_Side   Support  Confidence      Lift Right_Hand_Side
    0           light cream  0.004533    0.290598  4.843951         chicken
    1  mushroom cream sauce  0.005733    0.300699  3.790833        escalope
    2                 pasta  0.005866    0.372881  4.700812        escalope
    3         fromage blanc  0.003333    0.245098  5.164271           honey
    4         herb & pepper  0.015998    0.323450  3.291994     ground beef
    5          tomato sauce  0.005333    0.377358  3.840659     ground beef
    6           light cream  0.003200    0.205128  3.114710       olive oil
    7     whole wheat pasta  0.007999    0.271493  4.122410       olive oil
    8                 pasta  0.005066    0.322034  4.506672          shrimp
    


```python
print(output_data.nlargest(n=5, columns="Lift")) #상위 5개 출력
```

          Left_Hand_Side   Support  Confidence      Lift Right_Hand_Side
    3      fromage blanc  0.003333    0.245098  5.164271           honey
    0        light cream  0.004533    0.290598  4.843951         chicken
    2              pasta  0.005866    0.372881  4.700812        escalope
    8              pasta  0.005066    0.322034  4.506672          shrimp
    7  whole wheat pasta  0.007999    0.271493  4.122410       olive oil
    
<br>
<br>
#### 2-3-2. FP-Growth
- FP-Growth는 Frequent Pattern Growth를 뜻한다.<br>
- Apriori 알고리즘의 성능을 향상시키기 위해 개발되었다.(APriori와의 차이는 FP-Tree를 생성한 후 최소 지지도 이상의 패턴만을 추출한다는 것이다.)<br>

**FP-Tree만드는법**<br>
1. 데이터셋의 모든 데이터들에 대해 빈도를 계산한다.<br>
2. 시작 노드인 0 node를 만들고 각 instance를 하나씩 더해주면서 tree를 만든다. 이때, 빈도가 높은 item이 더 0에 가까운 node가 된다.<br>
3. 각 데이터들의 support를 구하고, 일정 값 이상의(정한 값) 지지도를 가지는 데이터들이 포함되는 가지만 남긴다.<br>
4. 3의 과정을 반복한다.<br>
<br>

fp-growth의 예제이다.<br>
*https://investraveler.tistory.com/233*의 코드를 사용했다.<br>

```python
import mlxtend
import numpy as np
import pandas as pd

data = np.array([
                 ['휴지','물티슈','샴푸'],
                 ['수세미','물티슈','비누'],
                 ['휴지','수세미','물티슈','비누'],
                 ['수세미','비누']
])

df_data = pd.DataFrame(data)
df_data

from mlxtend.preprocessing import TransactionEncoder
te = TransactionEncoder()
te_array = te.fit(data).transform(data)

df = pd.DataFrame(te_array, columns=te.columns_)

df
```
    


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>물티슈</th>
      <th>비누</th>
      <th>샴푸</th>
      <th>수세미</th>
      <th>휴지</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div>




```python
from mlxtend.frequent_patterns import fpgrowth
fpgrowth(df, min_support=0.5, use_colnames=True)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>support</th>
      <th>itemsets</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.75</td>
      <td>(물티슈)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.50</td>
      <td>(휴지)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.75</td>
      <td>(수세미)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.75</td>
      <td>(비누)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.50</td>
      <td>(비누, 물티슈)</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.50</td>
      <td>(수세미, 물티슈)</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.50</td>
      <td>(수세미, 비누, 물티슈)</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.50</td>
      <td>(휴지, 물티슈)</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.75</td>
      <td>(수세미, 비누)</td>
    </tr>
  </tbody>
</table>
</div>



<br>
<br>

*출처 :* <br>
- *2학년 1학기 데이터사이언스 강의자료* <br>
- *2학년 1학기 인공지능개론 강의자료* <br>
- *https://terryvery.tistory.com/93* <br>
- *https://m.blog.naver.com/sindong14/220661064114* <br>
- *https://process-mining.tistory.com/92* <br>
- *https://investraveler.tistory.com/233* <br>
